# LiteLLM Proxy Configuration for OneDay.run Platform

model_list:
  # Primary model - Claude Opus 4.5
  - model_name: claude-opus-4-5
    litellm_params:
      model: anthropic/claude-opus-4-5-20251101
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192

  # Secondary model - Claude Sonnet 4.5 (faster, cheaper)
  - model_name: claude-sonnet-4-5
    litellm_params:
      model: anthropic/claude-sonnet-4-5-20250929
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192

  # Fallback - Claude Haiku 4.5 (fastest, cheapest)
  - model_name: claude-haiku-4-5
    litellm_params:
      model: anthropic/claude-haiku-4-5-20251001
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 4096

  # OpenAI fallback (optional)
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 4096

# Router settings
router_settings:
  routing_strategy: simple-shuffle  # or: least-busy, usage-based-routing
  num_retries: 3
  retry_after: 5
  timeout: 120
  allowed_fails: 2
  cooldown_time: 60

# General settings
general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/DATABASE_URL
  
  # Cost tracking
  store_model_in_db: true
  
  # Rate limiting
  global_max_parallel_requests: 100
  
  # Logging
  log_level: INFO

# Litellm settings
litellm_settings:
  # Enable caching
  cache: true
  cache_params:
    type: redis
    host: redis
    port: 6379
    
  # Enable prompt caching for Anthropic
  enable_prompt_caching: true
  
  # Callbacks for monitoring
  success_callback: []
  failure_callback: []
  
  # Set default model
  default_model: claude-opus-4-5
  
  # Fallback models
  fallbacks:
    - claude-opus-4-5
    - claude-sonnet-4-5
    - gpt-4o

# Environment settings
environment_variables:
  ANTHROPIC_API_KEY: ""
  OPENAI_API_KEY: ""
  LITELLM_MASTER_KEY: "sk-oneday-master-key"
